{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sim Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "from translate import Translation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    TRAINING_DATA_PATH = './data/train.csv'\n",
    "    TRAINING_PAIRS_PATH = './data/train_pairs.csv'\n",
    "    PAIRS_LABEL_PATH = './data/pairs_label.csv'\n",
    "    CHOICE_FEATURE = ['name', 'latitude', 'longitude', 'city', 'state', 'zip', 'country', 'categories']\n",
    "\n",
    "    RAND_SEED = 3\n",
    "    TEST_SIZE = 0.2\n",
    "\n",
    "    BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                 id                     name   latitude   longitude  \\\n0  E_000001272c6c5d     Café Stad Oudenaarde  50.859975    3.634196   \n1  E_000002eae2a589           Carioca Manero -22.907225  -43.178244   \n2  E_000007f24ebc95         ร้านตัดผมการาเกด  13.780813  100.484900   \n3  E_000008a8ba4f48                 Turkcell  37.844510   27.844202   \n4  E_00001d92066153  Restaurante Casa Cofiño  43.338196   -4.326821   \n\n         city            state   zip country             categories  \\\n0  Nederename  Oost-Vlaanderen  9700      BE                   Bars   \n1         NaN              NaN   NaN      BR  Brazilian Restaurants   \n2         NaN              NaN   NaN      TH   Salons / Barbershops   \n3         NaN              NaN   NaN      TR     Mobile Phone Shops   \n4    Caviedes        Cantabria   NaN      ES    Spanish Restaurants   \n\n  point_of_interest  \n0  P_677e840bb6fc7e  \n1  P_d82910d8382a83  \n2  P_b1066599e78477  \n3  P_b2ed86905a4cd3  \n4  P_809a884d4407fb  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>city</th>\n      <th>state</th>\n      <th>zip</th>\n      <th>country</th>\n      <th>categories</th>\n      <th>point_of_interest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E_000001272c6c5d</td>\n      <td>Café Stad Oudenaarde</td>\n      <td>50.859975</td>\n      <td>3.634196</td>\n      <td>Nederename</td>\n      <td>Oost-Vlaanderen</td>\n      <td>9700</td>\n      <td>BE</td>\n      <td>Bars</td>\n      <td>P_677e840bb6fc7e</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E_000002eae2a589</td>\n      <td>Carioca Manero</td>\n      <td>-22.907225</td>\n      <td>-43.178244</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>BR</td>\n      <td>Brazilian Restaurants</td>\n      <td>P_d82910d8382a83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E_000007f24ebc95</td>\n      <td>ร้านตัดผมการาเกด</td>\n      <td>13.780813</td>\n      <td>100.484900</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>TH</td>\n      <td>Salons / Barbershops</td>\n      <td>P_b1066599e78477</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E_000008a8ba4f48</td>\n      <td>Turkcell</td>\n      <td>37.844510</td>\n      <td>27.844202</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>TR</td>\n      <td>Mobile Phone Shops</td>\n      <td>P_b2ed86905a4cd3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E_00001d92066153</td>\n      <td>Restaurante Casa Cofiño</td>\n      <td>43.338196</td>\n      <td>-4.326821</td>\n      <td>Caviedes</td>\n      <td>Cantabria</td>\n      <td>NaN</td>\n      <td>ES</td>\n      <td>Spanish Restaurants</td>\n      <td>P_809a884d4407fb</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(cfg.TRAINING_DATA_PATH)\n",
    "df = df[['id'] + cfg.CHOICE_FEATURE + ['point_of_interest']]\n",
    "# df = df[10000:20000].reset_index()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = df.fillna('NaN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def translate(data_list):\n",
    "    trans = Translation()\n",
    "    chunk_len = len(data_list) // 100\n",
    "    result = []\n",
    "    print(f'Chunk length: {chunk_len}')\n",
    "    for i in tqdm(range(100)):\n",
    "        start = i * chunk_len\n",
    "        stop = len(data_list) if i == 99 else (i + 1) * chunk_len\n",
    "        chunk = data_list[start:stop]\n",
    "        result.extend(trans.translate(chunk))\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating......\n",
      "Chunk length: 11388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:47<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name done.\n",
      "Chunk length: 11388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:25<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city done.\n",
      "Chunk length: 11388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:14<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state done.\n",
      "Chunk length: 11388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:14<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip done.\n",
      "Chunk length: 11388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:46<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country done.\n",
      "Chunk length: 11388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:19<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       id                          name   latitude  \\\n0        E_000001272c6c5d          Cafe City Oudenaarde  50.859975   \n1        E_000002eae2a589                Carioca Manero -22.907225   \n2        E_000007f24ebc95           karaage barber shop  13.780813   \n3        E_000008a8ba4f48                      Turkcell  37.844510   \n4        E_00001d92066153       Cofino House Restaurant  43.338196   \n...                   ...                           ...        ...   \n1138807  E_ffffb80854f713                     Blue frog  35.659020   \n1138808  E_ffffbf9a83e0ba                  Deshon Place  40.872116   \n1138809  E_ffffc572b4d35b  Izmir Adnan Menderes Airport  38.423733   \n1138810  E_ffffca745329ed       Yakiniku Japanese house  35.710712   \n1138811  E_ffffe6f4652fbb                   Waihi Beach -37.417042   \n\n          longitude          city          state       zip country  \\\n0          3.634196    Nederename  East Flanders      9700      BE   \n1        -43.178244           NaN            NaN       NaN      BR   \n2        100.484900           NaN            NaN       NaN      TH   \n3         27.844202           NaN            NaN       NaN      TR   \n4         -4.326821       cavides      cantabria       NaN      ES   \n...             ...           ...            ...       ...     ...   \n1138807  139.700780  Shibuya Ward          Tokyo  150-0043      JP   \n1138808  -79.945343        Butler             PA     16001      US   \n1138809   27.142826         İzmir            NaN       NaN      TR   \n1138810  139.775000         Taitō          Tokyo  110-0005      JP   \n1138811  175.950466   Waihi Beach  Bay Of Plenty      3611      NZ   \n\n                    categories point_of_interest  \n0                         Bars  P_677e840bb6fc7e  \n1        Brazilian Restaurants  P_d82910d8382a83  \n2         Salons / Barbershops  P_b1066599e78477  \n3           Mobile Phone Shops  P_b2ed86905a4cd3  \n4          Spanish Restaurants  P_809a884d4407fb  \n...                        ...               ...  \n1138807                    NaN  P_7ccbeab96cd82e  \n1138808   Housing Developments  P_db0abc418e7365  \n1138809       Airport Services  P_ae96252a6a9380  \n1138810             BBQ Joints  P_146662f246d418  \n1138811             Surf Spots  P_ea6578bf39b406  \n\n[1138812 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>city</th>\n      <th>state</th>\n      <th>zip</th>\n      <th>country</th>\n      <th>categories</th>\n      <th>point_of_interest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>E_000001272c6c5d</td>\n      <td>Cafe City Oudenaarde</td>\n      <td>50.859975</td>\n      <td>3.634196</td>\n      <td>Nederename</td>\n      <td>East Flanders</td>\n      <td>9700</td>\n      <td>BE</td>\n      <td>Bars</td>\n      <td>P_677e840bb6fc7e</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E_000002eae2a589</td>\n      <td>Carioca Manero</td>\n      <td>-22.907225</td>\n      <td>-43.178244</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>BR</td>\n      <td>Brazilian Restaurants</td>\n      <td>P_d82910d8382a83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E_000007f24ebc95</td>\n      <td>karaage barber shop</td>\n      <td>13.780813</td>\n      <td>100.484900</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>TH</td>\n      <td>Salons / Barbershops</td>\n      <td>P_b1066599e78477</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E_000008a8ba4f48</td>\n      <td>Turkcell</td>\n      <td>37.844510</td>\n      <td>27.844202</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>TR</td>\n      <td>Mobile Phone Shops</td>\n      <td>P_b2ed86905a4cd3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E_00001d92066153</td>\n      <td>Cofino House Restaurant</td>\n      <td>43.338196</td>\n      <td>-4.326821</td>\n      <td>cavides</td>\n      <td>cantabria</td>\n      <td>NaN</td>\n      <td>ES</td>\n      <td>Spanish Restaurants</td>\n      <td>P_809a884d4407fb</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1138807</th>\n      <td>E_ffffb80854f713</td>\n      <td>Blue frog</td>\n      <td>35.659020</td>\n      <td>139.700780</td>\n      <td>Shibuya Ward</td>\n      <td>Tokyo</td>\n      <td>150-0043</td>\n      <td>JP</td>\n      <td>NaN</td>\n      <td>P_7ccbeab96cd82e</td>\n    </tr>\n    <tr>\n      <th>1138808</th>\n      <td>E_ffffbf9a83e0ba</td>\n      <td>Deshon Place</td>\n      <td>40.872116</td>\n      <td>-79.945343</td>\n      <td>Butler</td>\n      <td>PA</td>\n      <td>16001</td>\n      <td>US</td>\n      <td>Housing Developments</td>\n      <td>P_db0abc418e7365</td>\n    </tr>\n    <tr>\n      <th>1138809</th>\n      <td>E_ffffc572b4d35b</td>\n      <td>Izmir Adnan Menderes Airport</td>\n      <td>38.423733</td>\n      <td>27.142826</td>\n      <td>İzmir</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>TR</td>\n      <td>Airport Services</td>\n      <td>P_ae96252a6a9380</td>\n    </tr>\n    <tr>\n      <th>1138810</th>\n      <td>E_ffffca745329ed</td>\n      <td>Yakiniku Japanese house</td>\n      <td>35.710712</td>\n      <td>139.775000</td>\n      <td>Taitō</td>\n      <td>Tokyo</td>\n      <td>110-0005</td>\n      <td>JP</td>\n      <td>BBQ Joints</td>\n      <td>P_146662f246d418</td>\n    </tr>\n    <tr>\n      <th>1138811</th>\n      <td>E_ffffe6f4652fbb</td>\n      <td>Waihi Beach</td>\n      <td>-37.417042</td>\n      <td>175.950466</td>\n      <td>Waihi Beach</td>\n      <td>Bay Of Plenty</td>\n      <td>3611</td>\n      <td>NZ</td>\n      <td>Surf Spots</td>\n      <td>P_ea6578bf39b406</td>\n    </tr>\n  </tbody>\n</table>\n<p>1138812 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Translating......')\n",
    "df['name'] = translate(df['name'].tolist())\n",
    "print('name done.')\n",
    "df['city'] = translate(df['city'].tolist())\n",
    "print('city done.')\n",
    "df['state'] = translate(df['state'].tolist())\n",
    "print('state done.')\n",
    "df['zip'] = translate(df['zip'].tolist())\n",
    "print('zip done.')\n",
    "df['country'] = translate(df['country'].tolist())\n",
    "print('country done.')\n",
    "df['categories'] = translate(df['categories'].tolist())\n",
    "print('categories done.')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [name1, latitude1, longitude1, city1, state1, zip1, country1, categories1, name2, latitude2, longitude2, city2, state2, zip2, country2, categories2]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name1</th>\n      <th>latitude1</th>\n      <th>longitude1</th>\n      <th>city1</th>\n      <th>state1</th>\n      <th>zip1</th>\n      <th>country1</th>\n      <th>categories1</th>\n      <th>name2</th>\n      <th>latitude2</th>\n      <th>longitude2</th>\n      <th>city2</th>\n      <th>state2</th>\n      <th>zip2</th>\n      <th>country2</th>\n      <th>categories2</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair1_cols = [feature + '1' for feature in cfg.CHOICE_FEATURE]\n",
    "pair2_cols = [feature + '2' for feature in cfg.CHOICE_FEATURE]\n",
    "pair_df = pd.DataFrame(columns=pair1_cols + pair2_cols)\n",
    "new_pair = pair_df.copy(deep=True)\n",
    "pair_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 739972/739972 [1:00:40<00:00, 203.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations: 672781\n",
      "Pair dataframe:\n",
      "                                                     name1  latitude1  \\\n",
      "0       Taichung International Airport (RMQ) (Taichung...  24.254227   \n",
      "1       Taichung International Airport (RMQ) (Taichung...  24.254227   \n",
      "2       Taichung International Airport (RMQ) (Taichung...  24.254227   \n",
      "3                         Taichung Airport Int'l Terminal  24.254209   \n",
      "4                         Taichung Airport Int'l Terminal  24.254209   \n",
      "...                                                   ...        ...   \n",
      "672776                    Forest Near Lebedyanskiye Ponds  55.775839   \n",
      "672777                                   Lebedyansky Pond  55.771589   \n",
      "672778                              Southern Highway, 30a  56.227364   \n",
      "672779                              Southern Highway, 30a  56.227364   \n",
      "672780                                        Yuzhka, 30a  56.227045   \n",
      "\n",
      "        longitude1            city1    state1   zip1 country1  \\\n",
      "0       120.599732         Taichung  Taichung  43346       TW   \n",
      "1       120.599732         Taichung  Taichung  43346       TW   \n",
      "2       120.599732         Taichung  Taichung  43346       TW   \n",
      "3       120.599844              NaN       NaN    NaN       TW   \n",
      "4       120.599844              NaN       NaN    NaN       TW   \n",
      "...            ...              ...       ...    ...      ...   \n",
      "672776   37.808085              NaN       NaN    NaN       RU   \n",
      "672777   37.818917              NaN       NaN    NaN       RU   \n",
      "672778   43.867168  Nizhny Novgorod       NaN    NaN       RU   \n",
      "672779   43.867168  Nizhny Novgorod       NaN    NaN       RU   \n",
      "672780   43.866928              NaN       NaN    NaN       RU   \n",
      "\n",
      "                                        categories1  \\\n",
      "0                          Airports, Military Bases   \n",
      "1                          Airports, Military Bases   \n",
      "2                          Airports, Military Bases   \n",
      "3                                 Airport Terminals   \n",
      "4                                 Airport Terminals   \n",
      "...                                             ...   \n",
      "672776                         Other Great Outdoors   \n",
      "672777                                        Parks   \n",
      "672778  Residential Buildings (Apartments / Condos)   \n",
      "672779  Residential Buildings (Apartments / Condos)   \n",
      "672780                              Assisted Living   \n",
      "\n",
      "                                  name2  latitude2  longitude2  \\\n",
      "0       Taichung Airport Int'l Terminal  24.254209  120.599844   \n",
      "1        Taichung International Airport   24.25548  120.600316   \n",
      "2             Taichung Qingquan Airport  24.214837  120.622577   \n",
      "3        Taichung International Airport   24.25548  120.600316   \n",
      "4             Taichung Qingquan Airport  24.214837  120.622577   \n",
      "...                                 ...        ...         ...   \n",
      "672776                 Lebedyansky Pond  55.776323   37.807971   \n",
      "672777                 Lebedyansky Pond  55.776323   37.807971   \n",
      "672778                      Yuzhka, 30a  56.227045   43.866928   \n",
      "672779                South Highway 30A   56.22763   43.866159   \n",
      "672780                South Highway 30A   56.22763   43.866159   \n",
      "\n",
      "                  city2  state2 zip2 country2  \\\n",
      "0                   NaN     NaN  NaN       TW   \n",
      "1                Taipei     NaN  NaN       TW   \n",
      "2                   NaN     NaN  NaN       TW   \n",
      "3                Taipei     NaN  NaN       TW   \n",
      "4                   NaN     NaN  NaN       TW   \n",
      "...                 ...     ...  ...      ...   \n",
      "672776           Moscow  Moscow  NaN       RU   \n",
      "672777           Moscow  Moscow  NaN       RU   \n",
      "672778              NaN     NaN  NaN       RU   \n",
      "672779  Nizhny Novgorod     NaN  NaN       RU   \n",
      "672780  Nizhny Novgorod     NaN  NaN       RU   \n",
      "\n",
      "                                        categories2  \n",
      "0                                 Airport Terminals  \n",
      "1                                          Airports  \n",
      "2                                          Airports  \n",
      "3                                          Airports  \n",
      "4                                          Airports  \n",
      "...                                             ...  \n",
      "672776                                        Lakes  \n",
      "672777                                        Lakes  \n",
      "672778                              Assisted Living  \n",
      "672779  Residential Buildings (Apartments / Condos)  \n",
      "672780  Residential Buildings (Apartments / Condos)  \n",
      "\n",
      "[672781 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for poi, poi_df in tqdm(df.groupby('point_of_interest')):\n",
    "    if len(poi_df) > 2:\n",
    "        poi_df = poi_df.drop(columns=['point_of_interest'])\n",
    "        new_pair = new_pair[0:0]\n",
    "        match_combs = np.array(list(combinations(poi_df['id'], 2)))\n",
    "        pair1 = pd.concat([poi_df[poi_df['id'] == comb][cfg.CHOICE_FEATURE] for comb in match_combs[:, 0]], ignore_index=True)\n",
    "        pair2 = pd.concat([poi_df[poi_df['id'] == comb][cfg.CHOICE_FEATURE] for comb in match_combs[:, 1]], ignore_index=True)\n",
    "        new_pair[pair1_cols] = pair1\n",
    "        new_pair[pair2_cols] = pair2\n",
    "        pair_df = pd.concat([pair_df, new_pair], ignore_index=True)\n",
    "        counter += len(match_combs)\n",
    "print(f'Total combinations: {counter}')\n",
    "print(f'Pair dataframe:\\n {pair_df}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Training Data\n",
    "1. How to build training data with positive / negative data?\n",
    "    - Total Data points: 1138812\n",
    "    - Total Data pairs: 672781\n",
    "    - Unique Data points: 739972\n",
    "    - For each data point, random sample 1 data point."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739972\n"
     ]
    }
   ],
   "source": [
    "print(len(df['point_of_interest'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pair1_cols = ['name1', 'latitude1', 'longitude1', 'city1', 'state1', 'zip1', 'country1', 'categories1']\n",
    "pair2_cols = ['name2', 'latitude2', 'longitude2', 'city2', 'state2', 'zip2', 'country2', 'categories2']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of same POI in df & shuffle_df: 3\n",
      "                                name1  latitude1  longitude1         city1  \\\n",
      "0                Cafe City Oudenaarde  50.859975    3.634196    Nederename   \n",
      "1                      Carioca Manero -22.907225  -43.178244           NaN   \n",
      "2                 karaage barber shop  13.780813  100.484900           NaN   \n",
      "3                            Turkcell  37.844510   27.844202           NaN   \n",
      "4             Cofino House Restaurant  43.338196   -4.326821       cavides   \n",
      "...                               ...        ...         ...           ...   \n",
      "1138807                     Blue frog  35.659020  139.700780  Shibuya Ward   \n",
      "1138808                  Deshon Place  40.872116  -79.945343        Butler   \n",
      "1138809  Izmir Adnan Menderes Airport  38.423733   27.142826         İzmir   \n",
      "1138810       Yakiniku Japanese house  35.710712  139.775000         Taitō   \n",
      "1138811                   Waihi Beach -37.417042  175.950466   Waihi Beach   \n",
      "\n",
      "                state1      zip1 country1            categories1  \\\n",
      "0        East Flanders      9700       BE                   Bars   \n",
      "1                  NaN       NaN       BR  Brazilian Restaurants   \n",
      "2                  NaN       NaN       TH   Salons / Barbershops   \n",
      "3                  NaN       NaN       TR     Mobile Phone Shops   \n",
      "4            cantabria       NaN       ES    Spanish Restaurants   \n",
      "...                ...       ...      ...                    ...   \n",
      "1138807          Tokyo  150-0043       JP                    NaN   \n",
      "1138808             PA     16001       US   Housing Developments   \n",
      "1138809            NaN       NaN       TR       Airport Services   \n",
      "1138810          Tokyo  110-0005       JP             BBQ Joints   \n",
      "1138811  Bay Of Plenty      3611       NZ             Surf Spots   \n",
      "\n",
      "                                                  name2  latitude2  \\\n",
      "0                            BINUS International School  -6.276083   \n",
      "1                                   Balconies of Tibana   4.610142   \n",
      "2                                    Jack in the Donuts  34.881460   \n",
      "3                       ANS CAMPUS EDUCATIONAL BUILDING  38.808738   \n",
      "4                                                  Muji  52.256692   \n",
      "...                                                 ...        ...   \n",
      "1138807                      Hua Chang Temple @ Lopburi  14.789094   \n",
      "1138808                                     Good coffee  37.499597   \n",
      "1138809                         Cala es clot de sa cera  39.985195   \n",
      "1138810  Subang Utama National Secondary School (SMKSU)   3.068102   \n",
      "1138811                                       Sun House -23.632122   \n",
      "\n",
      "         longitude2              city2                state2     zip2  \\\n",
      "0        106.668050  Tangerang, Banten                Banten    15322   \n",
      "1        -74.106977                NaN                   NaN      NaN   \n",
      "2        136.826005      Tokoname City      Aichi prefecture      NaN   \n",
      "3         30.535176                NaN                   NaN      NaN   \n",
      "4         20.985625             Warsaw  Masovian Voivodeship   00-175   \n",
      "...             ...                ...                   ...      ...   \n",
      "1138807  100.671540           Tha Sala              Lop Buri      NaN   \n",
      "1138808  127.027520              Seoul                   NaN  135-932   \n",
      "1138809    3.839948         Ciutadella      Balearic Islands    07769   \n",
      "1138810  101.581606        Subang Jaya              Selangor    47500   \n",
      "1138811  -46.708142          Sao Paulo                   NaN      NaN   \n",
      "\n",
      "        country2                                  categories2  \n",
      "0             ID                        Schools, High Schools  \n",
      "1             CO  Residential Buildings (Apartments / Condos)  \n",
      "2             JP                                  Donut Shops  \n",
      "3             TR                                 High Schools  \n",
      "4             PL                          Miscellaneous Shops  \n",
      "...          ...                                          ...  \n",
      "1138807       TH                             Buddhist Temples  \n",
      "1138808       KR                                 Coffee Shops  \n",
      "1138809       ES                                      Beaches  \n",
      "1138810       MY                 High Schools, Middle Schools  \n",
      "1138811       BR                      Furniture / Home Stores  \n",
      "\n",
      "[1138812 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "shuffle_df = df.sample(n=len(df), random_state=3, ignore_index=True)\n",
    "shuffle_pairs = pd.concat([df[cfg.CHOICE_FEATURE], shuffle_df[cfg.CHOICE_FEATURE]], axis=1)\n",
    "shuffle_pairs.columns = pair1_cols + pair2_cols\n",
    "print(f'Number of same POI in df & shuffle_df: '\n",
    "      f'{np.where(shuffle_df.point_of_interest == df.point_of_interest, True, False).sum()}')\n",
    "print(shuffle_pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_df = pd.concat([pair_df, shuffle_pairs], ignore_index=True)\n",
    "labels = pd.DataFrame(np.concatenate((np.ones(len(pair_df)), -(np.ones(len(df))))), columns=['label'])\n",
    "train_df.to_csv(cfg.TRAINING_PAIRS_PATH, index=False)\n",
    "labels.to_csv(cfg.PAIRS_LABEL_PATH, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:                                                 name   latitude   longitude  \\\n",
      "0  Taichung International Airport (RMQ) (Taichung...  24.254227  120.599732   \n",
      "1  Taichung International Airport (RMQ) (Taichung...  24.254227  120.599732   \n",
      "2  Taichung International Airport (RMQ) (Taichung...  24.254227  120.599732   \n",
      "3                    Taichung Airport Int'l Terminal  24.254209  120.599844   \n",
      "4                    Taichung Airport Int'l Terminal  24.254209  120.599844   \n",
      "\n",
      "       city     state    zip country                categories  \n",
      "0  Taichung  Taichung  43346      TW  Airports, Military Bases  \n",
      "1  Taichung  Taichung  43346      TW  Airports, Military Bases  \n",
      "2  Taichung  Taichung  43346      TW  Airports, Military Bases  \n",
      "3       NaN       NaN    NaN      TW         Airport Terminals  \n",
      "4       NaN       NaN    NaN      TW         Airport Terminals  \n",
      "Pair 2:                               name   latitude   longitude    city state  zip  \\\n",
      "0  Taichung Airport Int'l Terminal  24.254209  120.599844     NaN   NaN  NaN   \n",
      "1   Taichung International Airport   24.25548  120.600316  Taipei   NaN  NaN   \n",
      "2        Taichung Qingquan Airport  24.214837  120.622577     NaN   NaN  NaN   \n",
      "3   Taichung International Airport   24.25548  120.600316  Taipei   NaN  NaN   \n",
      "4        Taichung Qingquan Airport  24.214837  120.622577     NaN   NaN  NaN   \n",
      "\n",
      "  country         categories  \n",
      "0      TW  Airport Terminals  \n",
      "1      TW           Airports  \n",
      "2      TW           Airports  \n",
      "3      TW           Airports  \n",
      "4      TW           Airports  \n",
      "Labels:          label\n",
      "0          1.0\n",
      "1          1.0\n",
      "2          1.0\n",
      "3          1.0\n",
      "4          1.0\n",
      "...        ...\n",
      "1811588   -1.0\n",
      "1811589   -1.0\n",
      "1811590   -1.0\n",
      "1811591   -1.0\n",
      "1811592   -1.0\n",
      "\n",
      "[1811593 rows x 1 columns]\n",
      "Number of 1: label    672781.0\n",
      "dtype: float64\n",
      "Number of -1: label    1138812.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pair1_df = train_df[pair1_cols]\n",
    "pair2_df = train_df[pair2_cols]\n",
    "pair1_df.columns = cfg.CHOICE_FEATURE\n",
    "pair2_df.columns = cfg.CHOICE_FEATURE\n",
    "print(f'Pair 1: {pair1_df.head()}')\n",
    "print(f'Pair 2: {pair2_df.head()}')\n",
    "print(f'Labels: {labels}\\nNumber of 1: {labels[labels == 1].sum()}\\nNumber of -1: {-(labels[labels == -1].sum())}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Deep learning packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer, BertModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "random_seed(cfg.RAND_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def make_train_test_indices(dataset):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(cfg.TEST_SIZE * dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    return indices[split:], indices[:split]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def make_dataloader(dataset, indices, batch_size):\n",
    "    sampler = SubsetRandomSampler(indices)\n",
    "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler, num_workers=8, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Matching dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "class MatchingDataset(Dataset):\n",
    "    def __init__(self, pair1, pair2, labels):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.model = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.pair1 = pair1\n",
    "        self.pair2 = pair2\n",
    "        self.labels = labels\n",
    "        self.features = pair1.columns\n",
    "\n",
    "    def _encode_features(self, features):\n",
    "        pair1_input = [self.pair1[feat].tolist() for feat in features]\n",
    "        pair1_encode = [self._encode(feats) for feats in pair1_input]\n",
    "        pair2_input = [self.pair2[feat].tolist() for feat in features]\n",
    "        pair2_encode = [self._encode(feats) for feats in pair2_input]\n",
    "        self.pair1[features] = pd.DataFrame(pair1_encode)\n",
    "        self.pair2[features] = pd.DataFrame(pair2_encode)\n",
    "\n",
    "    def _get_features(self, idx, features):\n",
    "        return self.pair1.iloc[idx][features], self.pair2.iloc[idx][features]\n",
    "\n",
    "    def _encode(self, texts):\n",
    "        print(texts[0])\n",
    "        sent_token = [torch.IntTensor(self.tokenizer.encode(text)) for text in texts]\n",
    "        sent_token_padding = pad_sequence(sent_token, batch_first=True)\n",
    "        masks = torch.Tensor([[float(value > 0) for value in values] for values in sent_token_padding])\n",
    "        output = self.model(sent_token_padding, attention_mask=masks)\n",
    "        embedded = output[0][:, 0, :].squeeze()\n",
    "        return embedded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair1_feat, pair2_feat = self._get_features(idx, ['name', 'city', 'state', 'zip', 'country', 'categories'])\n",
    "        features = self._encode(pair1_feat.tolist() + pair2_feat.tolist())\n",
    "        pair1_feat = features[:6]\n",
    "        pair2_feat = features[6:]\n",
    "        return {\n",
    "            'pair1': {\n",
    "                'lat': self.pair1.iloc[idx]['latitude'],\n",
    "                'long': self.pair1.iloc[idx]['longitude'],\n",
    "                'name': pair1_feat[0],\n",
    "                'city': pair1_feat[1],\n",
    "                'state': pair1_feat[2],\n",
    "                'zip': pair1_feat[3],\n",
    "                'country': pair1_feat[4],\n",
    "                'categories': pair1_feat[5],\n",
    "            },\n",
    "            'pair2': {\n",
    "                'lat': self.pair2.iloc[idx]['latitude'],\n",
    "                'long': self.pair2.iloc[idx]['longitude'],\n",
    "                'name': pair2_feat[0],\n",
    "                'city': pair2_feat[1],\n",
    "                'state': pair2_feat[2],\n",
    "                'zip': pair2_feat[3],\n",
    "                'country': pair2_feat[4],\n",
    "                'categories': pair2_feat[5],\n",
    "            },\n",
    "            'label': int(self.labels.iloc[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MatchingDataset(pair1_df, pair2_df, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taichung International Airport (RMQ) (Taichung International Airport)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_99896/3507854315.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mitem\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_encode_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'name'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'city'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'state'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'zip'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'country'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'categories'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_99896/2891427710.py\u001B[0m in \u001B[0;36m_encode_features\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_encode_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0mpair1_input\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpair1\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeat\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mfeat\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0mpair1_encode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_encode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeats\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mfeats\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpair1_input\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpair1_encode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_99896/2891427710.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_encode_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0mpair1_input\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpair1\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeat\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mfeat\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0mpair1_encode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_encode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeats\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mfeats\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpair1_input\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpair1_encode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_99896/2891427710.py\u001B[0m in \u001B[0;36m_encode\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_encode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtexts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m         \u001B[0msent_token\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIntTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtexts\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m         \u001B[0msent_token_padding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpad_sequence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msent_token\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_first\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0mmasks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvalues\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msent_token_padding\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_99896/2891427710.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_encode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtexts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m         \u001B[0msent_token\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIntTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtexts\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m         \u001B[0msent_token_padding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpad_sequence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msent_token\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_first\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0mmasks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvalues\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msent_token_padding\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001B[0m in \u001B[0;36mencode\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001B[0m\n\u001B[1;32m   2238\u001B[0m                 method).\n\u001B[1;32m   2239\u001B[0m         \"\"\"\n\u001B[0;32m-> 2240\u001B[0;31m         encoded_inputs = self.encode_plus(\n\u001B[0m\u001B[1;32m   2241\u001B[0m             \u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2242\u001B[0m             \u001B[0mtext_pair\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtext_pair\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001B[0m in \u001B[0;36mencode_plus\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2568\u001B[0m         )\n\u001B[1;32m   2569\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2570\u001B[0;31m         return self._encode_plus(\n\u001B[0m\u001B[1;32m   2571\u001B[0m             \u001B[0mtext\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2572\u001B[0m             \u001B[0mtext_pair\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtext_pair\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils.py\u001B[0m in \u001B[0;36m_encode_plus\u001B[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    644\u001B[0m             )\n\u001B[1;32m    645\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 646\u001B[0;31m         \u001B[0mfirst_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_input_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    647\u001B[0m         \u001B[0msecond_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_input_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext_pair\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtext_pair\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    648\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils.py\u001B[0m in \u001B[0;36mget_input_ids\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m    613\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mget_input_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    614\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 615\u001B[0;31m                 \u001B[0mtokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    616\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_tokens_to_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    617\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils.py\u001B[0m in \u001B[0;36mtokenize\u001B[0;34m(self, text, **kwargs)\u001B[0m\n\u001B[1;32m    544\u001B[0m                 \u001B[0mtokenized_text\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    545\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 546\u001B[0;31m                 \u001B[0mtokenized_text\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    547\u001B[0m         \u001B[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    548\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtokenized_text\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/tokenization_bert.py\u001B[0m in \u001B[0;36m_tokenize\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    222\u001B[0m         \u001B[0msplit_tokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_basic_tokenize\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 224\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbasic_tokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnever_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall_special_tokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    225\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    226\u001B[0m                 \u001B[0;31m# If the token is part of the never_split set\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/tokenization_bert.py\u001B[0m in \u001B[0;36mtokenize\u001B[0;34m(self, text, never_split)\u001B[0m\n\u001B[1;32m    389\u001B[0m         \u001B[0;31m# union() returns a new set by concatenating the two sets.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    390\u001B[0m         \u001B[0mnever_split\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnever_split\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnever_split\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mnever_split\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnever_split\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 391\u001B[0;31m         \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_clean_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    392\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    393\u001B[0m         \u001B[0;31m# This was added on November 1st, 2018 for the multilingual and Chinese\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/tokenization_bert.py\u001B[0m in \u001B[0;36m_clean_text\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    491\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mcp\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mcp\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0xFFFD\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_is_control\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    492\u001B[0m                 \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 493\u001B[0;31m             \u001B[0;32mif\u001B[0m \u001B[0m_is_whitespace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    494\u001B[0m                 \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\" \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    495\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils.py\u001B[0m in \u001B[0;36m_is_whitespace\u001B[0;34m(char)\u001B[0m\n\u001B[1;32m    269\u001B[0m     \u001B[0;31m# \\t, \\n, and \\r are technically control characters but we treat them\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m     \u001B[0;31m# as whitespace since they are generally considered as such.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 271\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0mchar\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\" \"\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mchar\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"\\t\"\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mchar\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"\\n\"\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mchar\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"\\r\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    272\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    273\u001B[0m     \u001B[0mcat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0municodedata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcategory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "item = test_dataset._encode_features(['name', 'city', 'state', 'zip', 'country', 'categories'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading raw data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99896/903614112.py:1: DtypeWarning: Columns (5,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(cfg.TRAINING_PAIRS_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:                                                 name   latitude   longitude  \\\n",
      "0  Taichung International Airport (RMQ) (Taichung...  24.254227  120.599732   \n",
      "1  Taichung International Airport (RMQ) (Taichung...  24.254227  120.599732   \n",
      "2  Taichung International Airport (RMQ) (Taichung...  24.254227  120.599732   \n",
      "3                    Taichung Airport Int'l Terminal  24.254209  120.599844   \n",
      "4                    Taichung Airport Int'l Terminal  24.254209  120.599844   \n",
      "\n",
      "       city     state    zip country                categories  \n",
      "0  Taichung  Taichung  43346      TW  Airports, Military Bases  \n",
      "1  Taichung  Taichung  43346      TW  Airports, Military Bases  \n",
      "2  Taichung  Taichung  43346      TW  Airports, Military Bases  \n",
      "3      Null      Null   Null      TW         Airport Terminals  \n",
      "4      Null      Null   Null      TW         Airport Terminals  \n",
      "Pair 2:                               name   latitude   longitude    city state   zip  \\\n",
      "0  Taichung Airport Int'l Terminal  24.254209  120.599844    Null  Null  Null   \n",
      "1   Taichung International Airport  24.255480  120.600316  Taipei  Null  Null   \n",
      "2        Taichung Qingquan Airport  24.214837  120.622577    Null  Null  Null   \n",
      "3   Taichung International Airport  24.255480  120.600316  Taipei  Null  Null   \n",
      "4        Taichung Qingquan Airport  24.214837  120.622577    Null  Null  Null   \n",
      "\n",
      "  country         categories  \n",
      "0      TW  Airport Terminals  \n",
      "1      TW           Airports  \n",
      "2      TW           Airports  \n",
      "3      TW           Airports  \n",
      "4      TW           Airports  \n",
      "Total pair number: 1811593\n",
      "Labels:          label\n",
      "0          1.0\n",
      "1          1.0\n",
      "2          1.0\n",
      "3          1.0\n",
      "4          1.0\n",
      "...        ...\n",
      "1811588   -1.0\n",
      "1811589   -1.0\n",
      "1811590   -1.0\n",
      "1811591   -1.0\n",
      "1811592   -1.0\n",
      "\n",
      "[1811593 rows x 1 columns]\n",
      "Number of 1: label    672781.0\n",
      "dtype: float64\n",
      "Number of -1: label    1138812.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(cfg.TRAINING_PAIRS_PATH)\n",
    "train_df = train_df.fillna('Null')\n",
    "labels = pd.read_csv(cfg.PAIRS_LABEL_PATH)\n",
    "pair1_df = train_df[pair1_cols]\n",
    "pair2_df = train_df[pair2_cols]\n",
    "pair1_df.columns = cfg.CHOICE_FEATURE\n",
    "pair2_df.columns = cfg.CHOICE_FEATURE\n",
    "print(f'Pair 1: {pair1_df.head()}')\n",
    "print(f'Pair 2: {pair2_df.head()}')\n",
    "print(f'Total pair number: {len(train_df)}')\n",
    "print(f'Labels: {labels}\\nNumber of 1: {labels[labels == 1].sum()}\\nNumber of -1: {-(labels[labels == -1].sum())}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start build train / test dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matching_dataset = MatchingDataset(pair1_df, pair2_df, labels)\n",
    "train_indices, test_indices = make_train_test_indices(matching_dataset)\n",
    "train_loader = make_dataloader(matching_dataset, train_indices, cfg.BATCH_SIZE)\n",
    "test_loader = make_dataloader(matching_dataset, test_indices, cfg.BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}